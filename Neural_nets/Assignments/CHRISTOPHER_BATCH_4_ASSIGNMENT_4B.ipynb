{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHRISTOPHER_BATCH_4_ASSIGNMENT_4B.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/christopher11/machine-learning/blob/master/Neural_nets/Assignments/CHRISTOPHER_BATCH_4_ASSIGNMENT_4B.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "zunWodJ2Ya8u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Accuracy : 80.06 %"
      ]
    },
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69a2fc93-2af7-4a01-d85c-5d949cfd87c7"
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 256\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 12\n",
        "num_filter = 18\n",
        "compression = 0.6\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5f1ffb3d-274b-4810-d207-65c3c3d5132d"
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 32s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 32, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 32, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_filter = 12\n",
        "dropout_rate = 0.2\n",
        "l =12\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9744
        },
        "outputId": "f7cff981-4545-4f3d-b01c-8a0e59a67777"
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 32, 32, 12)   324         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 32, 32, 12)   48          conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 32, 32, 12)   0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 32, 32, 7)    756         activation_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_237 (Dropout)           (None, 32, 32, 7)    0           conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_225 (Concatenate)   (None, 32, 32, 19)   0           conv2d_241[0][0]                 \n",
            "                                                                 dropout_237[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 32, 32, 19)   76          concatenate_225[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 32, 32, 19)   0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 32, 32, 7)    1197        activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_238 (Dropout)           (None, 32, 32, 7)    0           conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_226 (Concatenate)   (None, 32, 32, 26)   0           concatenate_225[0][0]            \n",
            "                                                                 dropout_238[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 32, 32, 26)   104         concatenate_226[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 32, 32, 26)   0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 32, 32, 7)    1638        activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_239 (Dropout)           (None, 32, 32, 7)    0           conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_227 (Concatenate)   (None, 32, 32, 33)   0           concatenate_226[0][0]            \n",
            "                                                                 dropout_239[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 32, 32, 33)   132         concatenate_227[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 32, 32, 33)   0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 32, 32, 7)    2079        activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_240 (Dropout)           (None, 32, 32, 7)    0           conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_228 (Concatenate)   (None, 32, 32, 40)   0           concatenate_227[0][0]            \n",
            "                                                                 dropout_240[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 32, 32, 40)   160         concatenate_228[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 32, 32, 40)   0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 32, 32, 7)    2520        activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_241 (Dropout)           (None, 32, 32, 7)    0           conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_229 (Concatenate)   (None, 32, 32, 47)   0           concatenate_228[0][0]            \n",
            "                                                                 dropout_241[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 32, 32, 47)   188         concatenate_229[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 32, 32, 47)   0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 32, 32, 7)    2961        activation_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_242 (Dropout)           (None, 32, 32, 7)    0           conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_230 (Concatenate)   (None, 32, 32, 54)   0           concatenate_229[0][0]            \n",
            "                                                                 dropout_242[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 32, 32, 54)   216         concatenate_230[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 32, 32, 54)   0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 32, 32, 7)    3402        activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_243 (Dropout)           (None, 32, 32, 7)    0           conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_231 (Concatenate)   (None, 32, 32, 61)   0           concatenate_230[0][0]            \n",
            "                                                                 dropout_243[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 32, 32, 61)   244         concatenate_231[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 32, 32, 61)   0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 32, 32, 7)    3843        activation_248[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_244 (Dropout)           (None, 32, 32, 7)    0           conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_232 (Concatenate)   (None, 32, 32, 68)   0           concatenate_231[0][0]            \n",
            "                                                                 dropout_244[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 32, 32, 68)   272         concatenate_232[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 32, 32, 68)   0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 32, 32, 7)    4284        activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_245 (Dropout)           (None, 32, 32, 7)    0           conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_233 (Concatenate)   (None, 32, 32, 75)   0           concatenate_232[0][0]            \n",
            "                                                                 dropout_245[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 32, 32, 75)   300         concatenate_233[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 32, 32, 75)   0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 32, 32, 7)    4725        activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_246 (Dropout)           (None, 32, 32, 7)    0           conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_234 (Concatenate)   (None, 32, 32, 82)   0           concatenate_233[0][0]            \n",
            "                                                                 dropout_246[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 32, 32, 82)   328         concatenate_234[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 32, 32, 82)   0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 32, 32, 7)    5166        activation_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_247 (Dropout)           (None, 32, 32, 7)    0           conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_235 (Concatenate)   (None, 32, 32, 89)   0           concatenate_234[0][0]            \n",
            "                                                                 dropout_247[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 32, 32, 89)   356         concatenate_235[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 32, 32, 89)   0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 32, 32, 7)    5607        activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_248 (Dropout)           (None, 32, 32, 7)    0           conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_236 (Concatenate)   (None, 32, 32, 96)   0           concatenate_235[0][0]            \n",
            "                                                                 dropout_248[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 32, 32, 96)   384         concatenate_236[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 32, 32, 96)   0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 32, 32, 7)    672         activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_249 (Dropout)           (None, 32, 32, 7)    0           conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 16, 16, 7)    0           dropout_249[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 16, 16, 7)    28          average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 16, 16, 7)    0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 16, 16, 7)    441         activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_250 (Dropout)           (None, 16, 16, 7)    0           conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_237 (Concatenate)   (None, 16, 16, 14)   0           average_pooling2d_17[0][0]       \n",
            "                                                                 dropout_250[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 16, 16, 14)   56          concatenate_237[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 16, 16, 14)   0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 16, 16, 7)    882         activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_251 (Dropout)           (None, 16, 16, 7)    0           conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_238 (Concatenate)   (None, 16, 16, 21)   0           concatenate_237[0][0]            \n",
            "                                                                 dropout_251[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 16, 16, 21)   84          concatenate_238[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 16, 16, 21)   0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 16, 16, 7)    1323        activation_256[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_252 (Dropout)           (None, 16, 16, 7)    0           conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_239 (Concatenate)   (None, 16, 16, 28)   0           concatenate_238[0][0]            \n",
            "                                                                 dropout_252[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 16, 16, 28)   112         concatenate_239[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 16, 16, 28)   0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 16, 16, 7)    1764        activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_253 (Dropout)           (None, 16, 16, 7)    0           conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_240 (Concatenate)   (None, 16, 16, 35)   0           concatenate_239[0][0]            \n",
            "                                                                 dropout_253[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 16, 16, 35)   140         concatenate_240[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 16, 16, 35)   0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 16, 16, 7)    2205        activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_254 (Dropout)           (None, 16, 16, 7)    0           conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_241 (Concatenate)   (None, 16, 16, 42)   0           concatenate_240[0][0]            \n",
            "                                                                 dropout_254[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 16, 16, 42)   168         concatenate_241[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 16, 16, 42)   0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 16, 16, 7)    2646        activation_259[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_255 (Dropout)           (None, 16, 16, 7)    0           conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_242 (Concatenate)   (None, 16, 16, 49)   0           concatenate_241[0][0]            \n",
            "                                                                 dropout_255[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 16, 16, 49)   196         concatenate_242[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 16, 16, 49)   0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 16, 16, 7)    3087        activation_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_256 (Dropout)           (None, 16, 16, 7)    0           conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_243 (Concatenate)   (None, 16, 16, 56)   0           concatenate_242[0][0]            \n",
            "                                                                 dropout_256[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 16, 16, 56)   224         concatenate_243[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 16, 16, 56)   0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 16, 16, 7)    3528        activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_257 (Dropout)           (None, 16, 16, 7)    0           conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_244 (Concatenate)   (None, 16, 16, 63)   0           concatenate_243[0][0]            \n",
            "                                                                 dropout_257[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 16, 16, 63)   252         concatenate_244[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 16, 16, 63)   0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 16, 16, 7)    3969        activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_258 (Dropout)           (None, 16, 16, 7)    0           conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_245 (Concatenate)   (None, 16, 16, 70)   0           concatenate_244[0][0]            \n",
            "                                                                 dropout_258[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 16, 16, 70)   280         concatenate_245[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 16, 16, 70)   0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 16, 16, 7)    4410        activation_263[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_259 (Dropout)           (None, 16, 16, 7)    0           conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_246 (Concatenate)   (None, 16, 16, 77)   0           concatenate_245[0][0]            \n",
            "                                                                 dropout_259[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 16, 16, 77)   308         concatenate_246[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 16, 16, 77)   0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 16, 16, 7)    4851        activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_260 (Dropout)           (None, 16, 16, 7)    0           conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_247 (Concatenate)   (None, 16, 16, 84)   0           concatenate_246[0][0]            \n",
            "                                                                 dropout_260[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 16, 16, 84)   336         concatenate_247[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 16, 16, 84)   0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 16, 16, 7)    5292        activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_261 (Dropout)           (None, 16, 16, 7)    0           conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_248 (Concatenate)   (None, 16, 16, 91)   0           concatenate_247[0][0]            \n",
            "                                                                 dropout_261[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 16, 16, 91)   364         concatenate_248[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 16, 16, 91)   0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 16, 16, 7)    637         activation_266[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_262 (Dropout)           (None, 16, 16, 7)    0           conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 8, 8, 7)      0           dropout_262[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 8, 8, 7)      28          average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 8, 8, 7)      0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 8, 8, 7)      441         activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_263 (Dropout)           (None, 8, 8, 7)      0           conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_249 (Concatenate)   (None, 8, 8, 14)     0           average_pooling2d_18[0][0]       \n",
            "                                                                 dropout_263[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 8, 8, 14)     56          concatenate_249[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 8, 8, 14)     0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 8, 8, 7)      882         activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_264 (Dropout)           (None, 8, 8, 7)      0           conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_250 (Concatenate)   (None, 8, 8, 21)     0           concatenate_249[0][0]            \n",
            "                                                                 dropout_264[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 8, 8, 21)     84          concatenate_250[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 8, 8, 21)     0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 8, 8, 7)      1323        activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_265 (Dropout)           (None, 8, 8, 7)      0           conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_251 (Concatenate)   (None, 8, 8, 28)     0           concatenate_250[0][0]            \n",
            "                                                                 dropout_265[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 8, 8, 28)     112         concatenate_251[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 8, 8, 28)     0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 8, 8, 7)      1764        activation_270[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_266 (Dropout)           (None, 8, 8, 7)      0           conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_252 (Concatenate)   (None, 8, 8, 35)     0           concatenate_251[0][0]            \n",
            "                                                                 dropout_266[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 8, 8, 35)     140         concatenate_252[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 8, 8, 35)     0           batch_normalization_271[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 8, 8, 7)      2205        activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_267 (Dropout)           (None, 8, 8, 7)      0           conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_253 (Concatenate)   (None, 8, 8, 42)     0           concatenate_252[0][0]            \n",
            "                                                                 dropout_267[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 8, 8, 42)     168         concatenate_253[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 8, 8, 42)     0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 8, 8, 7)      2646        activation_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_268 (Dropout)           (None, 8, 8, 7)      0           conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_254 (Concatenate)   (None, 8, 8, 49)     0           concatenate_253[0][0]            \n",
            "                                                                 dropout_268[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 8, 8, 49)     196         concatenate_254[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 8, 8, 49)     0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 8, 8, 7)      3087        activation_273[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_269 (Dropout)           (None, 8, 8, 7)      0           conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_255 (Concatenate)   (None, 8, 8, 56)     0           concatenate_254[0][0]            \n",
            "                                                                 dropout_269[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 8, 8, 56)     224         concatenate_255[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 8, 8, 56)     0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 8, 8, 7)      3528        activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_270 (Dropout)           (None, 8, 8, 7)      0           conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_256 (Concatenate)   (None, 8, 8, 63)     0           concatenate_255[0][0]            \n",
            "                                                                 dropout_270[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 8, 8, 63)     252         concatenate_256[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 8, 8, 63)     0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 8, 8, 7)      3969        activation_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_271 (Dropout)           (None, 8, 8, 7)      0           conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_257 (Concatenate)   (None, 8, 8, 70)     0           concatenate_256[0][0]            \n",
            "                                                                 dropout_271[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 8, 8, 70)     280         concatenate_257[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 8, 8, 70)     0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 8, 8, 7)      4410        activation_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_272 (Dropout)           (None, 8, 8, 7)      0           conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_258 (Concatenate)   (None, 8, 8, 77)     0           concatenate_257[0][0]            \n",
            "                                                                 dropout_272[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 8, 8, 77)     308         concatenate_258[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 8, 8, 77)     0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 8, 8, 7)      4851        activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_273 (Dropout)           (None, 8, 8, 7)      0           conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_259 (Concatenate)   (None, 8, 8, 84)     0           concatenate_258[0][0]            \n",
            "                                                                 dropout_273[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 8, 8, 84)     336         concatenate_259[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 8, 8, 84)     0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 8, 8, 7)      5292        activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_274 (Dropout)           (None, 8, 8, 7)      0           conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_260 (Concatenate)   (None, 8, 8, 91)     0           concatenate_259[0][0]            \n",
            "                                                                 dropout_274[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 8, 8, 91)     364         concatenate_260[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 8, 8, 91)     0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 8, 8, 7)      637         activation_279[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_275 (Dropout)           (None, 8, 8, 7)      0           conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_19 (AveragePo (None, 4, 4, 7)      0           dropout_275[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 4, 4, 7)      28          average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 4, 4, 7)      0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 4, 4, 7)      441         activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_276 (Dropout)           (None, 4, 4, 7)      0           conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_261 (Concatenate)   (None, 4, 4, 14)     0           average_pooling2d_19[0][0]       \n",
            "                                                                 dropout_276[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 4, 4, 14)     56          concatenate_261[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 4, 4, 14)     0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, 4, 4, 7)      882         activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_277 (Dropout)           (None, 4, 4, 7)      0           conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_262 (Concatenate)   (None, 4, 4, 21)     0           concatenate_261[0][0]            \n",
            "                                                                 dropout_277[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_282 (BatchN (None, 4, 4, 21)     84          concatenate_262[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_282 (Activation)     (None, 4, 4, 21)     0           batch_normalization_282[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 4, 4, 7)      1323        activation_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_278 (Dropout)           (None, 4, 4, 7)      0           conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_263 (Concatenate)   (None, 4, 4, 28)     0           concatenate_262[0][0]            \n",
            "                                                                 dropout_278[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 4, 4, 28)     112         concatenate_263[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, 4, 4, 28)     0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 4, 4, 7)      1764        activation_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_279 (Dropout)           (None, 4, 4, 7)      0           conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_264 (Concatenate)   (None, 4, 4, 35)     0           concatenate_263[0][0]            \n",
            "                                                                 dropout_279[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 4, 4, 35)     140         concatenate_264[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 4, 4, 35)     0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 4, 4, 7)      2205        activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_280 (Dropout)           (None, 4, 4, 7)      0           conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_265 (Concatenate)   (None, 4, 4, 42)     0           concatenate_264[0][0]            \n",
            "                                                                 dropout_280[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 4, 4, 42)     168         concatenate_265[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 4, 4, 42)     0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 4, 4, 7)      2646        activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_281 (Dropout)           (None, 4, 4, 7)      0           conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_266 (Concatenate)   (None, 4, 4, 49)     0           concatenate_265[0][0]            \n",
            "                                                                 dropout_281[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 4, 4, 49)     196         concatenate_266[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 4, 4, 49)     0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 4, 4, 7)      3087        activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_282 (Dropout)           (None, 4, 4, 7)      0           conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_267 (Concatenate)   (None, 4, 4, 56)     0           concatenate_266[0][0]            \n",
            "                                                                 dropout_282[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 4, 4, 56)     224         concatenate_267[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 4, 4, 56)     0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 4, 4, 7)      3528        activation_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_283 (Dropout)           (None, 4, 4, 7)      0           conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_268 (Concatenate)   (None, 4, 4, 63)     0           concatenate_267[0][0]            \n",
            "                                                                 dropout_283[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 4, 4, 63)     252         concatenate_268[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 4, 4, 63)     0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 4, 4, 7)      3969        activation_288[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_284 (Dropout)           (None, 4, 4, 7)      0           conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_269 (Concatenate)   (None, 4, 4, 70)     0           concatenate_268[0][0]            \n",
            "                                                                 dropout_284[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 4, 4, 70)     280         concatenate_269[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 4, 4, 70)     0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 4, 4, 7)      4410        activation_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_285 (Dropout)           (None, 4, 4, 7)      0           conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_270 (Concatenate)   (None, 4, 4, 77)     0           concatenate_269[0][0]            \n",
            "                                                                 dropout_285[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 4, 4, 77)     308         concatenate_270[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, 4, 4, 77)     0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 4, 4, 7)      4851        activation_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_286 (Dropout)           (None, 4, 4, 7)      0           conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_271 (Concatenate)   (None, 4, 4, 84)     0           concatenate_270[0][0]            \n",
            "                                                                 dropout_286[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 4, 4, 84)     336         concatenate_271[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, 4, 4, 84)     0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 4, 4, 7)      5292        activation_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_287 (Dropout)           (None, 4, 4, 7)      0           conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_272 (Concatenate)   (None, 4, 4, 91)     0           concatenate_271[0][0]            \n",
            "                                                                 dropout_287[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 4, 4, 91)     364         concatenate_272[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, 4, 4, 91)     0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_20 (AveragePo (None, 2, 2, 91)     0           activation_292[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 364)          0           average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           3650        flatten_5[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 157,744\n",
            "Trainable params: 152,518\n",
            "Non-trainable params: 5,226\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        },
        "outputId": "ea5a8d44-3a52-43bf-a6a0-f4feabc08791"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 157s 3ms/step - loss: 1.7543 - acc: 0.3451 - val_loss: 2.4378 - val_acc: 0.2849\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 135s 3ms/step - loss: 1.4047 - acc: 0.4793 - val_loss: 1.6993 - val_acc: 0.3964\n",
            "Epoch 3/50\n",
            " 9216/50000 [====>.........................] - ETA: 1:43 - loss: 1.2999 - acc: 0.5204"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 135s 3ms/step - loss: 1.2597 - acc: 0.5364 - val_loss: 1.2204 - val_acc: 0.5646\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 135s 3ms/step - loss: 1.1531 - acc: 0.5793 - val_loss: 1.3178 - val_acc: 0.5565\n",
            "Epoch 5/50\n",
            "29952/50000 [================>.............] - ETA: 50s - loss: 1.0809 - acc: 0.6113"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 1.0698 - acc: 0.6148 - val_loss: 1.2935 - val_acc: 0.5844\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 1.0136 - acc: 0.6319 - val_loss: 1.0223 - val_acc: 0.6415\n",
            "Epoch 7/50\n",
            "34816/50000 [===================>..........] - ETA: 37s - loss: 0.9606 - acc: 0.6550"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.9597 - acc: 0.6547 - val_loss: 1.1130 - val_acc: 0.6274\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.9159 - acc: 0.6704 - val_loss: 1.0883 - val_acc: 0.6399\n",
            "Epoch 9/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.8873 - acc: 0.6802"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.8836 - acc: 0.6816 - val_loss: 1.0762 - val_acc: 0.6466\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.8572 - acc: 0.6903 - val_loss: 1.0218 - val_acc: 0.6568\n",
            "Epoch 11/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.8289 - acc: 0.7026"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.8244 - acc: 0.7038 - val_loss: 1.0118 - val_acc: 0.6535\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.8035 - acc: 0.7097 - val_loss: 1.0840 - val_acc: 0.6454\n",
            "Epoch 13/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.7869 - acc: 0.7167"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.7829 - acc: 0.7181 - val_loss: 1.0196 - val_acc: 0.6612\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.7601 - acc: 0.7267 - val_loss: 0.8647 - val_acc: 0.7076\n",
            "Epoch 15/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.7395 - acc: 0.7361"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.7418 - acc: 0.7337 - val_loss: 1.0349 - val_acc: 0.6616\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.7182 - acc: 0.7442 - val_loss: 1.0007 - val_acc: 0.6829\n",
            "Epoch 17/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.6951 - acc: 0.7526"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.6994 - acc: 0.7507 - val_loss: 1.1950 - val_acc: 0.6262\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.6914 - acc: 0.7528 - val_loss: 0.8326 - val_acc: 0.7291\n",
            "Epoch 19/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.6655 - acc: 0.7643"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.6681 - acc: 0.7639 - val_loss: 0.9460 - val_acc: 0.6999\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.6557 - acc: 0.7647 - val_loss: 0.8947 - val_acc: 0.7132\n",
            "Epoch 21/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.6471 - acc: 0.7694"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.6444 - acc: 0.7704 - val_loss: 1.0295 - val_acc: 0.6789\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.6354 - acc: 0.7733 - val_loss: 0.7779 - val_acc: 0.7477\n",
            "Epoch 23/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.6238 - acc: 0.7792"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.6224 - acc: 0.7793 - val_loss: 1.3038 - val_acc: 0.6329\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.6111 - acc: 0.7838 - val_loss: 0.7237 - val_acc: 0.7659\n",
            "Epoch 25/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.6009 - acc: 0.7851"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.5987 - acc: 0.7866 - val_loss: 0.7795 - val_acc: 0.7446\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.5946 - acc: 0.7884 - val_loss: 0.8129 - val_acc: 0.7465\n",
            "Epoch 27/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.5866 - acc: 0.7926"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.5827 - acc: 0.7940 - val_loss: 1.3247 - val_acc: 0.6403\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.5740 - acc: 0.7962 - val_loss: 0.7361 - val_acc: 0.7613\n",
            "Epoch 29/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.5614 - acc: 0.8006"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.5681 - acc: 0.7979 - val_loss: 0.7172 - val_acc: 0.7717\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.5529 - acc: 0.8040 - val_loss: 0.9506 - val_acc: 0.7198\n",
            "Epoch 31/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.5493 - acc: 0.8055"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.5536 - acc: 0.8036 - val_loss: 0.7874 - val_acc: 0.7565\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.5419 - acc: 0.8077 - val_loss: 0.6891 - val_acc: 0.7820\n",
            "Epoch 33/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.5360 - acc: 0.8097"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.5392 - acc: 0.8090 - val_loss: 1.0100 - val_acc: 0.6979\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.5295 - acc: 0.8126 - val_loss: 0.9779 - val_acc: 0.7112\n",
            "Epoch 35/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.5224 - acc: 0.8149"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.5240 - acc: 0.8148 - val_loss: 0.8170 - val_acc: 0.7512\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.5192 - acc: 0.8162 - val_loss: 0.7638 - val_acc: 0.7668\n",
            "Epoch 37/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.5014 - acc: 0.8219"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.5083 - acc: 0.8194 - val_loss: 0.6984 - val_acc: 0.7771\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.5080 - acc: 0.8191 - val_loss: 0.7921 - val_acc: 0.7653\n",
            "Epoch 39/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.4955 - acc: 0.8226"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.5007 - acc: 0.8203 - val_loss: 0.6935 - val_acc: 0.7792\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.4968 - acc: 0.8247 - val_loss: 0.8384 - val_acc: 0.7518\n",
            "Epoch 41/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.4884 - acc: 0.8258"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.4908 - acc: 0.8252 - val_loss: 0.6522 - val_acc: 0.7959\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.4909 - acc: 0.8258 - val_loss: 0.6381 - val_acc: 0.8028\n",
            "Epoch 43/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.4771 - acc: 0.8301"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.4802 - acc: 0.8302 - val_loss: 0.6192 - val_acc: 0.8012\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.4735 - acc: 0.8294 - val_loss: 0.6850 - val_acc: 0.7882\n",
            "Epoch 45/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.4655 - acc: 0.8328"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.4691 - acc: 0.8315 - val_loss: 0.8951 - val_acc: 0.7444\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.4690 - acc: 0.8330 - val_loss: 0.8214 - val_acc: 0.7581\n",
            "Epoch 47/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.4647 - acc: 0.8362"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.4678 - acc: 0.8354 - val_loss: 0.7013 - val_acc: 0.7847\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.4595 - acc: 0.8365 - val_loss: 0.6516 - val_acc: 0.7949\n",
            "Epoch 49/50\n",
            "35840/50000 [====================>.........] - ETA: 35s - loss: 0.4538 - acc: 0.8390"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 134s 3ms/step - loss: 0.4578 - acc: 0.8386 - val_loss: 0.7819 - val_acc: 0.7725\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 136s 3ms/step - loss: 0.4539 - acc: 0.8386 - val_loss: 0.6593 - val_acc: 0.8006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7d674b1668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "1fdf005a-0336-426a-9d0c-a8590cfb403a"
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 15s 1ms/step\n",
            "Test loss: 0.6592810513496399\n",
            "Test accuracy: 0.8006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bdcc071-6be9-4f8d-8d37-d82acb4d4eed"
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Og56VCRh5j8V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}